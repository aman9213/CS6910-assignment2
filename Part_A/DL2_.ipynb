{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMAtLTyARjh5"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader \n",
        "import pathlib\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "79d4HO-gR2qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### mounting google drive on colab"
      ],
      "metadata": {
        "id": "1JyBhoQCR41L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qsIqSYeRx-r",
        "outputId": "36b0279d-2c8e-4ba4-9203-d91caa18f359"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### extracting zip file"
      ],
      "metadata": {
        "id": "58-CO5ZeSIpz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_ref = zipfile.ZipFile('/content/drive/MyDrive/nature_12K.zip', 'r') #Opens the zip file in read mode\n",
        "zip_ref.extractall('/nature') #Extracts the files into the /nature folder\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "dSSkIY1hR_nQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "id": "-7_hOs7ESw62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "# how many samples per batch to load\n",
        "batch_size = 64\n",
        "# percentage of training set to use as validation\n",
        "valid_size = 0.2\n",
        "\n",
        "#To unzip dataset in colab\n",
        "data_dir='/nature/inaturalist_12K'\n",
        "\n",
        "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
        "                                       transforms.RandomResizedCrop(200),\n",
        "                                       transforms.RandomHorizontalFlip(),\n",
        "\n",
        "                                       transforms.ToTensor(),\n",
        "                                       \n",
        "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                            [0.229, 0.224, 0.225])])\n",
        "\n",
        "test_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
        "                                      transforms.RandomResizedCrop(200),\n",
        "                                     \n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                           [0.229, 0.224, 0.225])])\n",
        "\n",
        "# Pass transforms in here, then run the next cell to see how the transforms look\n",
        "train_data = torchvision.datasets.ImageFolder(data_dir + '/train', transform=train_transforms)\n",
        "test_data = torchvision.datasets.ImageFolder(data_dir + '/val', transform=test_transforms)\n",
        "num_train = len(train_data)\n",
        "indices = list(range(num_train))\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(valid_size * num_train))\n",
        "train_idx, valid_idx = indices[split:], indices[:split]\n",
        "\n",
        "# define samplers for obtaining training and validation batches\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "# prepare data loaders (combine dataset and sampler)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
        "    sampler=train_sampler)\n",
        "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
        "    sampler=valid_sampler)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)\n",
        "print(len(valid_loader))\n"
      ],
      "metadata": {
        "id": "Se-bds4oS0vT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path='/nature/inaturalist_12K/train'\n",
        "test_path='/nature/inaturalist_12K/val'\n",
        "print(len(train_loader))\n"
      ],
      "metadata": {
        "id": "qRaHeWTlxe5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root=pathlib.Path(train_path)\n",
        "classes=sorted([j.name.split('/')[-1] for j in root.iterdir()])\n",
        "classes=(classes[1:])\n",
        "print(classes)"
      ],
      "metadata": {
        "id": "81TZUn74xqXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_count=len(glob.glob(train_path+'/**/*.jpg'))\n",
        "train_count=int(train_count-train_count*0.2)             \n",
        "test_count=len(glob.glob(test_path+'/**/*.jpg'))\n",
        "val_count=int(train_count*0.2)"
      ],
      "metadata": {
        "id": "Ns9hZzIIyKx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# K=32\n",
        "# S=3\n",
        "# batch_norm=True\n",
        "# activation='Relu'\n",
        "# nodes=512\n",
        "class ConvNet(nn.Module):\n",
        "  def __init__(self,epoch,K,S,factor,activation,batch_norm,drop_out,nodes,num_class=10):\n",
        "    \n",
        "    super(ConvNet,self).__init__()\n",
        "    \n",
        "    self.batch_norm=batch_norm\n",
        "    \n",
        "    self.conv1=nn.Conv2d(in_channels=3,out_channels=K,kernel_size=S,stride=1,padding=(S-1)//2) #its output size will be=(batch=256,K,200,200)\n",
        "    \n",
        "    if self.batch_norm=='Yes':\n",
        "      self.bn1=nn.BatchNorm2d(K)\n",
        "      \n",
        "    if activation=='Relu':\n",
        "      \n",
        "      self.activ1=nn.ReLU()\n",
        "    elif activation=='Gelu':\n",
        "    \n",
        "      self.activ1=nn.GELU()\n",
        "    elif activation=='Silu':\n",
        "      \n",
        "      self.activ1=nn.SiLU()\n",
        "    elif activation=='Mish':\n",
        "      \n",
        "      self.activ1=nn.Mish()\n",
        "      \n",
        "    self.maxpool1=nn.MaxPool2d(kernel_size=2)## shape=(256,K,100,100)\n",
        "    \n",
        "    K_prev=K\n",
        "    K=int(K*factor)\n",
        "    #layer 2\n",
        "    self.conv2=nn.Conv2d(in_channels=K_prev,out_channels=K,kernel_size=S,stride=1,padding=(S-1)//2) #its output size will be=(batch=256,K,100,100)\n",
        "    if self.batch_norm=='Yes':\n",
        "      self.bn2=nn.BatchNorm2d(K)\n",
        "    if activation=='Relu':\n",
        "      self.activ2=nn.ReLU()\n",
        "    elif activation=='Gelu':\n",
        "      self.activ2=nn.GELU()\n",
        "    elif activation=='Silu':\n",
        "      self.activ2=nn.SiLU()\n",
        "    elif activation=='Mish':\n",
        "      self.activ2=nn.Mish()\n",
        "    self.maxpool2=nn.MaxPool2d(kernel_size=2)\n",
        "    ##shape=(256,K,50,50)\n",
        "    K_prev=K\n",
        "    K=int(K*factor)\n",
        "    # layer 3\n",
        "    self.conv3=nn.Conv2d(in_channels=K_prev,out_channels=K,kernel_size=S,stride=1,padding=(S-1)//2) #its output size will be=(batch=256,K,50,50)\n",
        "    if self.batch_norm=='Yes':\n",
        "      self.bn3=nn.BatchNorm2d(K)\n",
        "    if activation=='Relu':\n",
        "      self.activ3=nn.ReLU()\n",
        "    elif activation=='Gelu':\n",
        "      self.activ3=nn.GELU()\n",
        "    elif activation=='Silu':\n",
        "      self.activ3=nn.SiLU()\n",
        "    elif activation=='Mish':\n",
        "      self.activ3=nn.Mish()\n",
        "    self.maxpool3=nn.MaxPool2d(kernel_size=2)\n",
        "    ##shape=(256,K,25,25)\n",
        "    K_prev=K\n",
        "    K=int(K*factor)\n",
        "    #layer 4\n",
        "    self.conv4=nn.Conv2d(in_channels=K_prev,out_channels=K,kernel_size=S,stride=1,padding=(S-1)//2) #its output size will be=(batch=256,K,25,25)\n",
        "    if self.batch_norm=='Yes':\n",
        "      self.bn4=nn.BatchNorm2d(K)\n",
        "    if activation=='Relu':\n",
        "      self.activ4=nn.ReLU()\n",
        "    elif activation=='Gelu':\n",
        "      self.activ4=nn.GELU()\n",
        "    elif activation=='Silu':\n",
        "      self.activ4=nn.SiLU()\n",
        "    elif activation=='Mish':\n",
        "      self.activ4=nn.Mish()\n",
        "    self.maxpool4=nn.MaxPool2d(kernel_size=2)\n",
        "    ## shape=(256,K,12,12)\n",
        "    K_prev=K\n",
        "    K=int(K*factor)\n",
        "    #layer 5\n",
        "    self.conv5=nn.Conv2d(in_channels=K_prev,out_channels=K,kernel_size=S,stride=1,padding=(S-1)//2) #its output size will be=(batch=256,K,12,12)\n",
        "    if self.batch_norm=='Yes':\n",
        "      self.bn5=nn.BatchNorm2d(K)\n",
        "    if activation=='Relu':\n",
        "      self.activ5=nn.ReLU()\n",
        "    elif activation=='Gelu':\n",
        "      self.activ5=nn.GELU()\n",
        "    elif activation=='Silu':\n",
        "      self.activ5=nn.SiLU()\n",
        "    elif activation=='Mish':\n",
        "      self.activ5=nn.Mish()\n",
        "    self.maxpool5=nn.MaxPool2d(kernel_size=2)\n",
        "    ## shape(256,K,6,6)\n",
        "    #print(len(self.maxpool5))\n",
        "     ## shape(256,K,)\n",
        "    ## FC layer\n",
        "    self.dropout1=nn.Dropout(drop_out)            ### ADD DROPOUT HERE\n",
        "    #print(\"D:\",self.dropout1.shape)\n",
        "    self.fc1=nn.Linear(in_features=6*6*K,out_features=nodes)\n",
        "    self.dropout2=nn.Dropout(drop_out)   ### ADD DROP OUT HERE\n",
        "    self.fc2=nn.Linear(in_features=nodes,out_features=10)\n",
        "    self.K=K\n",
        "    ##feed forward\n",
        "\n",
        "  def forward(self,x):\n",
        "    \n",
        "    out=self.conv1(x)\n",
        "    if self.batch_norm=='Yes':\n",
        "      out=self.bn1(out)\n",
        "    out=self.activ1(out)\n",
        "    out=self.maxpool1(out)\n",
        "\n",
        "    out=self.conv2(out)\n",
        "    if self.batch_norm=='Yes':\n",
        "      out=self.bn2(out)\n",
        "    out=self.activ2(out)\n",
        "    out=self.maxpool2(out)\n",
        "\n",
        "    out=self.conv3(out)\n",
        "    if self.batch_norm=='Yes':\n",
        "      out=self.bn3(out)\n",
        "    out=self.activ3(out)\n",
        "    out=self.maxpool3(out)\n",
        "\n",
        "    out=self.conv4(out)\n",
        "    if self.batch_norm=='Yes':\n",
        "      out=self.bn4(out)\n",
        "    out=self.activ4(out)\n",
        "    out=self.maxpool4(out)\n",
        "    \n",
        "    out=self.conv5(out)\n",
        "    if self.batch_norm=='Yes':\n",
        "      out=self.bn5(out)\n",
        "    out=self.activ5(out)\n",
        "    out=self.maxpool5(out)\n",
        "    \n",
        "    out=self.dropout1(out)\n",
        "    b,c,d,e=out.shape\n",
        "    \n",
        "    out=out.view(-1,d*e*self.K)  ###### there is some problem\n",
        "    \n",
        "    out=self.fc1(out)\n",
        "    out=self.dropout2(out)\n",
        "    out=self.fc2(out)\n",
        "    out=F.softmax(out,dim=1)\n",
        "    \n",
        "    return out\n",
        "\n",
        "\n",
        "epoch,K,S,factor,activation,batch_norm,drop_out,nodes=2,32,3,1/2,'Relu','Yes',0.2,512\n",
        "net=ConvNet(epoch,K,S,factor,activation,batch_norm,drop_out,nodes,num_class=10)\n",
        "print(net)"
      ],
      "metadata": {
        "id": "PF8byTONx-4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.autograd import Variable\n",
        "##model training\n",
        "\n",
        "best_accuracy=0\n",
        "\n",
        "for epoch in range(10):\n",
        "\n",
        "  model.train()\n",
        "  train_accuracy=0.0\n",
        "  train_loss=0.0\n",
        "  for i,(images,labels) in enumerate(train_loader):\n",
        "    \n",
        "    if torch.cuda.is_available():\n",
        "      images=Variable(images.cuda())\n",
        "      labels=Variable(labels.cuda())\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    outputs=model(images)\n",
        "    loss=loss_fun(outputs,labels)\n",
        "    #print(loss)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    #print(loss.cpu().data)\n",
        "    train_loss+=loss.cpu().data*images.size(0)\n",
        "    _,prediction=torch.max(outputs.data,1)\n",
        "\n",
        "    train_accuracy+=int(torch.sum(prediction==labels.data))\n",
        "  train_accuracy=train_accuracy/train_count\n",
        "  train_loss=train_loss/train_count\n",
        "\n",
        "  ##evalution on testing data\n",
        "  model.eval()\n",
        "\n",
        "  test_accuracy=0.0\n",
        "\n",
        "  for i,(images,labels) in enumerate(test_loader):\n",
        "    if torch.cuda.is_available():\n",
        "      images=Variable(images.cuda())\n",
        "      labels=Variable(labels.cuda())\n",
        "      \n",
        "    outputs=model(images)\n",
        "\n",
        "    _,prediction=torch.max(outputs.data,1)\n",
        "    test_accuracy+=int(torch.sum(prediction==labels.data))\n",
        "  \n",
        "  test_accuracy=test_accuracy/test_count\n",
        "\n",
        "\n",
        "  print('Epoch:'+str(epoch)+'Train Loss:'+str(int(train_loss))+'Train accuracy'+str(train_accuracy)+'Test accuracy'+str(test_accuracy))\n",
        "  \n",
        "  if test_accuracy>best_accuracy:\n",
        "    torch.save(model.state_dict(),'best_checkpoint.model')\n",
        "    best_accuracy=test_accuracy\n"
      ],
      "metadata": {
        "id": "EgAKo9etyfth"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}